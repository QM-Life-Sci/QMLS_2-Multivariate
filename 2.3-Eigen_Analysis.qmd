---
title: "Eigenanalysis"
subtitle: "Consolidating Variance"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
bibliography: Multivariate.bib
csl: evolution.csl
---

## Eigenanalysis

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(smatr)
library(cowplot)
library(factoextra)
library(readxl)
library(GGally)
library(palmerpenguins)

ggplot2::theme_set(theme_cowplot())
```

- A way to summarize the patterns of variance
- A way to rotate or repackage data while preserving the patterns
- Applies to square matrices (e.g., a correlation matrix)

For more information see Tabachnick and Fidell [-@Tabachnick2019-tl] and Bakker [-@Bakker2024-mg]


## Eigenvalues ($x$) and Eigenvectors ($\lambda$)

- The set of values that satisfy the following equation:

\begin{align*}

              Ax &= \lambda x\\
(A - \lambda I)x &= 0

\end{align*}

- The number of solutions to this equation will be the same as the number of rows & columns (i.e., the number of variables)
- Each solution is a pair of an eigenvalue and eigenvector


## Solving for eigenvalues and eigenvectors 
  
```{r}
#| echo: true

MM <- matrix(1:9, nrow = 3)

EE <- eigen(MM)

EE$values   # Eigenvalues
```
<br/>
```{r}
#| echo: true
EE$vectors  # Eigenvectors

```


## Solving for eigenvalues and eigenvectors 
  
$$Ax = \lambda x$$

```{r}
#| echo: true

MM %*% EE$vectors[ , 1, drop = FALSE]

EE$values[1] * EE$vectors[ , 1, drop = FALSE]

```


## Eigenanalysis and Multivariate Methods

- Performing an eigenanalysis on a covariance or correlation matrix 
- Allows us to consolidate and reorganize data without changing the relationships between data points
- Creates new variables that are combinations of variables


## PCA Example: Penguins

- Drop any rows with missing values
- Center and scale all variables

```{r}
#| echo: true

glimpse(penguins)

penguins_vars <- penguins |>
  dplyr::select(body_mass_g, ends_with("_mm")) |>
  drop_na() |>
  mutate_all(~(scale(.)))
```


## PCA Example: Penguins

```{r}
#| echo: true

ggscatmat(penguins_vars) 

```


## Covariance Matrix

Because variables are standardized, `cor(penguins_vars)` == `cov(penguins_vars)`

```{r}
#| echo: true

(pen_cov <- cov(penguins_vars))

cor(penguins_vars)
```


## PCA & Eigenanalysis

```{r}
#| echo: true

EE <- eigen(pen_cov)
EE$values
EE$vectors

pen_pca <- prcomp(penguins_vars, center = TRUE, scale. = TRUE)
pen_pca$sdev^2  # prcomr() returns sd
pen_pca$rotation

```


## Consolidating Variance

```{r}
#| echo: true

pen_cov

#total variation 
sum(diag(pen_cov))

#transformed correlation matrix after eigenanalysis
round(cov(pen_pca$x), digits = 10)
#total variation
sum(diag(cov(pen_pca$x)))

```


## Rotating Data

- Consider just 2 variables for visualization of the process

```{r}

p1 <- penguins_vars |>
  ggplot(aes(body_mass_g, flipper_length_mm)) +
  geom_point()

p2 <- penguins |>
  ggplot(aes(body_mass_g, flipper_length_mm)) +
  geom_point()

plot_grid(p1,p2, ncol=2)

```


## Rotating Data

```{r}

ma <- line.cis(penguins_vars$body_mass_g, penguins_vars$flipper_length_mm,
               method = "MA")

p3 <- p1 + 
  geom_abline(slope = ma[2, 1], intercept = ma[1, 1],
              color = "red",
              linewidth = 1.5) +
  geom_abline(slope = -1/ma[2, 1],
              intercept = mean(penguins_vars$body_mass_g) - -1/ma[2, 1] * 
                mean(penguins_vars$flipper_length_mm),
              color = "red",
              size = 1.5) +
  coord_fixed()

p3
```

## Rotating Data 

```{r}

pc2 <- prcomp(penguins_vars[c(1,4)], center = TRUE, scale. = TRUE)
pc_p <- tibble(PC1 = pc2$x[,1],
               PC2 = pc2$x[,2])

p4 <- ggplot(pc_p, aes(PC1,PC2)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", size = 1.5) +
  geom_vline(xintercept = 0, color = "red", size = 1.5)
p4
```



## Rotating Data 

- Identifying and computing a new coordinate system for the data
- Observations have the same relationship WRT one another
- Set of composite variables that are uncorrelated
- Variables have redistributed variances


## Finding the new coordinate system

$$P = SZ^{T}$$

- $P$ is the matrix of PC scores
- $S$ is the unknown transformation matrix
- $Z^T$ is the transpose of the standardized data matrix


## Finding the new coordinate system

We can calculate this from: eigenvectors, eigenvalues, covariance matrix, and the data matrix.

```{r}
#| echo: true

L_mat <- pen_pca$rotation %*% (pen_pca$sdev^2 * diag(x = 4))

PC_scores <- t(L_mat) %*% solve(pen_cov) %*% t(penguins_vars)

t(PC_scores[,1:5])

pen_pca$x[1:5,]

```


## Finding the new coordinate system

- From the equations of the composite variables
- Coefficients are given by the eigenvectors

$$PC1_{i} = \beta_{1}z_{1,i} + \beta_{2}z_{2,i} + \beta_{3}z_{3,i} + \beta_{4}z_{4,i}$$

- $\beta_1 \dots \beta_4$ are the 4 elements of the PC1 column of the rotation matrix
- $z_{1,i} \dots z_{4,i}$ is the *i*th row of the data


## Finding the new coordinate system

```{r}
#| echo: true
eig1 <- pen_pca$rotation[,"PC1"]
o1 <- penguins_vars[1,]
eig1
o1
sum(eig1*o1)
pen_pca$x[1,1]
```


## How much does each variable contribute to the composite?

- Eigenvectors = standardized coefficients
- Loadings = correlation of each variable with each PC
- Loadings are eigenvectors scaled by the standard deviation of each PC
    - Warning: R calls the eigenvectors "loadings"


## How much does each variable contribute to the composite?

```{r}
#| echo: true

pen_pca$rotation 

pen_pca$rotation[ , "PC2"] * pen_pca$sdev[2]

cor(penguins_vars, pen_pca$x)
```

## Biplot

```{r}
fviz_pca_var(pen_pca, addlabels = TRUE, repel = TRUE)
```


## References

::: {#refs}
:::
