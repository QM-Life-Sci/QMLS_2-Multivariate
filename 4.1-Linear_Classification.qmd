---
title: "Linear Classification"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
bibliography: Multivariate.bib
csl: evolution.csl
---

## Linear Classification

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(cowplot)
library(GGally)
library(plotly)
library(MASS)
library(mvtnorm)
library(nnet)
library(broom)

set.seed(87231)

ggplot2::theme_set(theme_cowplot())

set.seed(347977)
n <- 100

sigma <- rbind(c(1.0, 0.3),
               c(0.3, 1.0))
G1 <- rmvnorm(n = n, mean = c(-2, -2), sigma = sigma)
G2 <- rmvnorm(n = n, mean = c(0, 2), sigma = sigma)
G <- data.frame(rbind(G1, G2))

SD2 <- data.frame(Group = factor(rep(LETTERS[1:2], each = n)),
                 G)
set.seed(347977)
n <- 100

sigma <- rbind(c(1.0, 0.3),
               c(0.3, 1.0))
G1 <- rmvnorm(n = n, mean = c(-2, -2), sigma = sigma)
G2 <- rmvnorm(n = n, mean = c(0, 2), sigma = sigma)
G3 <- rmvnorm(n = n, mean = c(2, -1), sigma = sigma)
G <- data.frame(rbind(G1, G2, G3))

SD3 <- data.frame(Group = factor(rep(LETTERS[1:3], each = n)),
                 G)

write_rds(SD2, file = "Data/SD2.rds")
write_rds(SD3, file = "Data/SD3.rds")

```

- Classification methods use multivariate data to *classify* observations into groups
- Methods when group membership is known ("supervised")
  - LDA, SVM, CART
- Methods when group membership is unknown ("unsupervised")
  - Clustering (many methods)
 
## DFA/LDA is the converse of MANOVA 

**MANOVA**:

`Height + Mouth_Diam + Tube_Diam + Keel_Diam ~ Site`

How well can a categorical predictor variable jointly predict a multivariate set of outcome variables?

**Discriminant Function Analysis aka Linear Discriminant Analysis**

`Site ~ Height + Mouth_Diam + Tube_Diam + Keel_Diam`

How well can a multivariate set of variables predict group membership (a categorical variable)? 


## LDA is the converse of MANOVA

- MANOVA emphasizes decision-making (hypothesis testing) and asking if groups are different
- LDA emphasizes prediction of group membership
  - Which predictors relate to group differences
- Mathematically they do the same thing

## Simulated Data

```{r}
#| echo: true
nn <- 25
dat <- tibble(y1 = c(rnorm(nn),rnorm(nn,2)),
              y2 = c(rnorm(nn),rnorm(nn,2)),
              y3 = c(rnorm(nn),rnorm(nn,2)),
              xx = rep(c("A","B"), each = nn))
```


## Simulated Data

```{r}
#| warning: false

fig <- plot_ly() |>
  add_markers(data = dat,
              x = ~ y1,
              y = ~ y2,
              z = ~ y3,
              color = ~ xx,
              marker = list(size = 5),
              showlegend = FALSE) |>
  layout(scene = list(xaxis = list(title = 'y1'),
                      yaxis = list(title = 'y2'),
                      zaxis = list(title = 'y3')))

fig
```

## LDA

- `lda()` is the function to perform linear discriminant analysis in R

```{r}
#| echo: true

MM <- lda(xx ~ y1 + y2 + y3, data = dat)
MM$scaling
```

## LDA

- identifies the composite that maximally separates the groups on the dimensions of the response variable
- MANOVA performs an ANOVA using this composite as the response variable

$$Y_{composite} = 0.74~y_{1} + 0.49~y_{2} + 0.47~y_{3}$$

## Visualize for 2 continuous variables and 2 groups

```{r}
#| echo: true 

set.seed(347977)
n <- 100

sigma <- rbind(c(1.0, 0.4),
               c(0.4, 1.0))
G1 <- rmvnorm(n = n, mean = c(-1, 1), sigma = sigma)
G2 <- rmvnorm(n = n, mean = c(2, 3), sigma = sigma)
G <- data.frame(rbind(G1, G2))

dat <- data.frame(Group = factor(rep(LETTERS[1:2], each = n)), G)

dat <- dat |>
  mutate(x1_s = scale(X1),
         x2_s = scale(X2))

dfa <- lda(Group ~ X1 + X2, data = dat)
dfa$scaling
```

## Visualize for 2 continuous variables and 2 groups

```{r}
#| echo: true
#| output-location: slide
#| fig-width: 7
#| fig-height: 5
#| fig-align: center

dat |>
  ggplot(aes(x1_s,x2_s, color = Group)) +
  geom_point(size = 4) + 
  geom_abline(intercept=0, slope = -dfa$scaling[1]/dfa$scaling[2], linewidth = 2)

```

$$Y_{composite} = ~LD1~x_{s1} + LD2~x_{s2}$$

$$x_{s2} = -\frac{LD1}{LD2}~x_{s1}$$

## Visualize for 2 continuous variables and 2 groups

```{r}
#| echo: true
#| output-location: slide
#| fig-width: 7
#| fig-height: 5
#| fig-align: center

dat$ycomp <- dfa$scaling[1]*dat$x1_s + dfa$scaling[2]*dat$x2_s
  
dat |>
  ggplot(aes(Group,ycomp, color = Group)) +
  geom_point(size = 4, position = position_jitter(width = 0.2))

```

## PCA vs LDA

- LDA also maximizes the separation between groups

```{r}

pcaM <- prcomp(~X1+X2, data=dat, center =TRUE, scale.=TRUE)
dat$pc1 <- pcaM$x[,1]
dat$pc2 <- pcaM$x[,2]

dmean <- dat |>
  group_by(Group) |>
  summarize(m_pca = mean(pc1), m_dfa = mean(ycomp))

dat |>
  ggplot(aes(ycomp,pc1, color = Group)) +
  geom_point(size = 4) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  xlab("LDA score") +
  ylab("PC1 score") +
  annotate("text", x = -0.5, y = 2.5, label = paste0("A = ",length(which(dat$ycomp<0 & dat$Group=="A")),"\n","B = ",length(which(dat$ycomp<0 & dat$Group=="B"))
)) +
  annotate("text", x = 0.5, y = 2.5, label = paste0("A = ",length(which(dat$ycomp>0 & dat$Group=="A")),"\n","B = ",length(which(dat$ycomp>0 & dat$Group=="B"))
))+
  annotate("text", x = -2, y = -0.5, label = paste0("A = ",length(which(dat$pc1<0 & dat$Group=="A")),"\n","B = ",length(which(dat$pc1<0 & dat$Group=="B"))
))+
  annotate("text", x = -2, y = 0.5, label = paste0("A = ",length(which(dat$pc1>0 & dat$Group=="A")),"\n","B = ",length(which(dat$pc1>0 & dat$Group=="B"))
))
  
```

## Biological Example: Diet-Dependent Gene Expression in Fruit Flies

![](./Images/Fly_iis.jpg){fig-align="center"}


```{r}

FD <- read_csv("./Data/PreProcessed_Expr.csv",
               show_col_types = FALSE) |> 
  dplyr::select(-patRIL) |> 
  mutate(Treat = factor(Treat)) |> 
  as.data.frame()


```

## Fly LDA

```{r}
#| echo: true

Flda <- lda(Treat ~ ., data = FD)

Flda$scaling[1:5,]

```

## LDA with the `candisc` package

- First fit a multivariate `lm()`
- Then use `candisc` to perform lda

```{r}
#| echo: true

library(candisc)

man1 <- lm(as.matrix(FD[,2:ncol(FD)]) ~ FD$Treat)
can_lda <- candisc(man1)

```

## Contribution of variables

```{r}
#| echo: true

can_lda$coeffs.raw[1:5,]
can_lda$coeffs.std[1:5,]

```


## Contribution of variables

- Correlations between standardized variables and the linear discriminant scores 

```{r}
#| echo: true

ss <- predict(Flda)$x

cor(ss[,1], FD[,2:6])

can_lda$structure[1:5,1]

```

## LDA for Classification

- Can you accurately predict the diet from the composite gene expression score?

```{r}
#| echo: true

pred.val <- predict(Flda)

TT <- table(Original = FD$Treat, Predicted = pred.val$class)
TT
(sum(diag(TT))/sum(TT))* 100

```

## LDA for Classification

- Can you accurately predict an unseen diet from the composite score?

```{r}
#| echo: true

Flda_cv <- lda(Treat ~ ., data = FD, CV = TRUE)

TT <- table(Original = FD$Treat, Predicted = Flda_cv$class)
TT
(sum(diag(TT))/sum(TT))* 100

```

## Logistic regression vs. LDA

Both:

- Which variable(s) are good predictors of group membership
- Groups are known *a priori*
- Uses linear combinations of variables
- **Predict new observations**

## Logistic regression vs. LDA

Differences:

- Some assumptions
- Predictive ability (depends on specifics)
- See: [this stackexchange](https://stats.stackexchange.com/questions/95247/logistic-regression-vs-lda-as-two-class-classifiers)
- Ease of interpretation for different questions

## Fly Multinomial Regression

```{r}
#| echo: true

F.mn <- multinom(Treat ~ ., data = FD)

```


## Fly Multinomial Regression

```{r}
#| echo: true

tidy(F.mn, conf.int = TRUE)

predict(F.mn, FD[1,2:ncol(FD)])

```



## References

::: {#refs}
:::
