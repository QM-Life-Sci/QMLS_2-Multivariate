---
title: "Classification and Regression Trees"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
bibliography: Multivariate.bib
csl: evolution.csl
---


```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(cowplot)

ggplot2::theme_set(theme_cowplot())

SD2 <- read_rds("Data/SD2.rds")
SD3 <- read_rds("Data/SD3.rds")
```

## CRAN Taskview

[Machine Learning](https://cran.r-project.org/web/views/MachineLearning.html)


## *Classification* and *Regression* Trees

- Original description [@Breiman1984-vv]
- Non-technical introduction [@Fielding2006-xa]
- Introduction for ecologists [@Elith2008-qs]

[`rpart`: Recursive Partitioning and Regression Trees](https://cran.r-project.org/package=rpart) and `rpart.plot` for plotting


## Methodology

Series of if-else splits

- Like a species key
    - Variables can be reused
- "Recursive partitioning"
  - No limit to the number of splits that can happen
  - *Post hoc* tree pruning is necessary


## CART Schematic

![](https://www.geo.fu-berlin.de/en/v/geo-it/gee/3-classification/3-1-methodical-background/3-1-1-cart/dectree.png){fig-align="center"}


## Challenges

- What combination of splits is "best"?
- When is a node a leaf (terminal)?
- Computationally challenging for large numbers of predictors and/or data


## Very general method

- Do not have to conform to distributional requirements of multivariate normality
    - Most any kind of data will work
- Creates a set of thresholds for partitioning
- Robust to extreme values
    - Become their own leaf node


## Drawbacks

- Thresholds do not *necessarily* have any biological meaning
- Overfitting is easy (train/test is essential)


## Data setup

```{r}
#| echo: true

library(rpart)
library(rpart.plot)
library(rsample)

set.seed(34598734)

split <- initial_split(SD3, strata = Group, prop = 0.75) 

Training_set <- training(split) 
Test_set <- testing(split)
```


## Building the CART

- `cp` controls the threshold for keeping a split

```{r}
#| echo: true
#| output-location: slide
tree <- rpart(Group ~ X1 + X2, data = Training_set,
              control = rpart.control(cp = 0.01))
tree
```


## Summarizing

```{r}
printcp(tree)
```


## Pruning

- Identify best `cp` value to use
- Prune the tree based on the best cp value

```{r}
#| echo: true

best <- tree$cptable[which.min(tree$cptable[ , "xerror"]), "CP"]
pruned_tree <- prune(tree, cp = best)
```

```{r}
tree$cptable
```


## Plot the pruned tree

```{r}
#| echo: true

prp(pruned_tree,
    faclen = 0,
    extra = 1,
    roundint = FALSE,
    digits = 3)
```


## Default plot

```{r}
#| echo: true

rpart.plot(pruned_tree)
```


## Prediction

```{r}
#| echo: true

pred.tree <- predict(pruned_tree, Test_set, type = "class")
table(pred.tree, Test_set$Group)
mean(pred.tree == Test_set$Group) * 100
```


## Application to fly diet experiment

```{r}
#| echo: true

FD <- read_csv("./Data/PreProcessed_Expr.csv",
               show_col_types = FALSE) |> 
  dplyr::select(-patRIL) |> 
  mutate(Treat = factor(Treat)) |> 
  as.data.frame()

set.seed(94875)

split <- initial_split(FD, strata = Treat, prop = 0.75) 

Training_set <- training(split) 
Test_set <- testing(split)
```


## CART building

```{r}
#| echo: true

set.seed(98715)
tree <- rpart(Treat ~ .,
              data = Training_set,
              control = rpart.control(cp = 0.01))
tree
```


## Summarizing

```{r}
printcp(tree)
```


## Pruning

```{r}
#| echo: true

best <- tree$cptable[which.min(tree$cptable[ , "xerror"]), "CP"]
pruned_tree <- prune(tree, cp = best)
```

```{r}
tree$cptable
```


## Plot the pruned tree

```{r}
#| echo: true

prp(pruned_tree,
    faclen = 0,
    extra = 1,
    roundint = FALSE,
    digits = 3)
```


## Default plot

```{r}
#| echo: true

rpart.plot(pruned_tree)
```


## Prediction

```{r}
#| echo: true

pred.tree <- predict(pruned_tree, Test_set, type = "class")
table(pred.tree, Test_set$Treat)
mean(pred.tree == Test_set$Treat) * 100
```


## Multivariate Regression Trees



## References

::: {#refs}
:::

