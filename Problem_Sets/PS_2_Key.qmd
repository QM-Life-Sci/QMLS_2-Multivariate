---
title: "Problem Set 2"
author:
  - Your Name Here
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    toc-title: Contents
code-annotations: hover
---


```{r}
#| label: setup
#| echo: true
#| message: false
#| warning: false

#FIXME

library(tidyverse)
library(cowplot)
library(mvtnorm)
library(readxl)
library(factoextra)


theme_set(theme_cowplot())

```

## Solving a linear model with matrix algebra

In QMLS 1, we used the `Birds.xlsx` file, which contains data from Vuilleumier, F. (1970) Insular Biogeography in Continental Regions. I. The Northern Andes of South America. *American Naturalist* 104:373-388.

This paper explores the numbers of bird species in isolated "islands" of pÃ¡ramo vegetation in the Andes. The Missouri Botanical Garden can [explain it better than we can](http://bit.ly/1PNWfsq):

> Within the tropical regions of Mexico, Central and South America, Africa, Malesia including New Guinea, and Hawaii, there is a vegetation type that occurs between the upper limit of continuous, closed-canopy forest (i.e., forest line or timberline) and the upper limit of plant life (i.e., snow line) that is characterized by tussock grasses, large rosette plants, shrubs with evergreen, coriaceous and sclerophyllous leaves, and cushion plants.  This vegetation type is scattered along the crests of the highest mountain ranges or on isolated mountaintops between about 3000 meters (m) and 5000 m, like islands in a sea of forest.

We used these data to see what the best predictor(s) of bird abundance is/are. The data contain species abundance (`N_Species`) and geographical information for 14 "islands". Other data include:

1. `Area`: "Island" size (thousands of square km)
1. `Elevation`: Elevation (thousands of meters)
1. `Dist_to_Ecuador`: Distance to Ecuador (km)
1. `Dist_to_Island`: Distance to nearest island (km)

Read in the data and create the correlation matrix for all variables except location.

```{r}
#FIXME

MM <- read_excel("../Data/Birds.xlsx")

cor(MM[,2:6])
```

Does anything stand out in the correlation matrix to make you concerned about using multiple regression to analyze these data?

> No, the pairwise correlations are all reasonable. The largest is ~-0.7.

Fit a linear model wherein species abundance is predicted by the other four variables as we did in QMLS 1. Note the coefficients for each predictor. 

```{r}
# FIXME
fm <- lm(N_Species ~ Area + Elevation + Dist_to_Ecuador + Dist_to_Island,
         data = MM)
summary(fm)
```

Use the following equation from lecture to use matrix algebra to solve for the coefficients:

$$B = \left(X^T ~ X \right)^{-1}~\left( X^T~y \right)$$
where $X$ is the matrix of predictor variables and $y$ is the matrix containing the reponse variable. Use `model.matrix()` to obtain $X$. The $X$ matrix should have a column of 1's for the intercept followed by a column containing each predictor. You may want to compute each component of the equation separately first, rather than trying to do the equation in one line. Compare your result to the coefficients in the model summary you obtained above.

```{r}
#FIXME

X <- model.matrix(N_Species ~ Area + Elevation + Dist_to_Ecuador + Dist_to_Island,
                   data = MM)  
y <- as.matrix(MM[,2])

solve(t(X) %*% X) %*% (t(X) %*% y)

coef(fm)
```

Use the coefficients you've calculated to interpret this model, including your interpretation of the intercept. 

> The number of species increases with area, elevation, and distance to island. It decreases with distance to Ecuador. When the predictors are all 0, the model still predicts ~28 species will be present. #FIXME

We might wish to fit a model "without" an intercept, which will constrain the intercept to be zero using the `- 1` syntax. Also use matrix math to calculate these coefficients. 

```{r}
#FIXME

fm0 <- lm(N_Species ~ Area + Elevation + Dist_to_Ecuador + Dist_to_Island - 1,
         data = MM)
coef(fm0)

X <- as.matrix(MM[,3:6])
solve(t(X) %*% X) %*% (t(X) %*% y)

```


## Simulated data and shared variance 

Let's explore how different amounts of shared variance influence the outcome of PCA. Simulate three different datasets each consisting of 8 variables. In each, simulate data such that the 8 variables all have the same correlation ranging from low shared variance (correlations all = 0.05), medium (correlations all = 0.5), and high (correlations all = 0.9) 

The steps will be: 

1. Create a 8x8 square correlation matrix. First, fill the entire matrix with the desired correlation between your predictors. Then use `diag` to set the diagonal elements to 1. 
1. Use `rmvnorm` to simulate your data. For the means, choose any 8 random values between 1 and 30 using `runif()`.
1. Perform a PCA using `prcomp`. Examine the rotation and summary to interpret the new composite variables. 
1. Make a biplot to help visualize what is happening in each case. Note you are only generating positive correlations so the plot might look more lopsided than a typical dataset.

```{r}
#FIXME

set.seed(254683)

ccs <- c(0.05, 0.5, 0.9)

for(cc in ccs)
{
sigma <- matrix(cc, nrow=8, ncol=8)
diag(sigma) <- 1

MM <- rmvnorm(n = 800, mean = runif(8,1,30), sigma = sigma)

pp <- prcomp(MM, center=TRUE, scale.=TRUE)
print(pp)
print(summary(pp))
print(fviz_pca_var(pp, addlabels = TRUE, repel = TRUE))
}

```

How does the PCA change as the amount of shared variance increases? 

> When there is more shared variation (higher correlations) the first PC explains a larger proportion of the variance and the loadings of the individual predictors trend in the same direction. When the correlations between variables are lower, the predictors load more evenly on differnt PCs and the initial PCs account for less variation. #FIXME


## Sets of shared variance

In the previous simulation, we created variables all with equal correlation. Let's create a data set with two sets of variables each correlated with each other but not highly correlated with the other set. You want to make a correlation matrix that looks like this:

![](https://i.imgur.com/DcBAMmF.png){fig-align="center" width=50%}

As above, simulate your data, run a PCA, and examine the output and biplot. 

```{r}
#FIXME

sigma <- matrix(0.05, nrow=6, ncol=6)
diag(sigma) <- 1
sigma[1,2] <- 0.9
sigma[2,1] <- 0.9
sigma[2,3] <- -0.8
sigma[1,3] <- -0.8
sigma[3,1] <- -0.8
sigma[3,2] <- -0.8
sigma[4,5] <- 0.5
sigma[5,4] <- 0.5
sigma[5,6] <- 0.5
sigma[6,5] <- 0.5
sigma[4,6] <- 0.5
sigma[6,4] <-0.5

MM <- rmvnorm(n = 800, mean = runif(6,1,30), sigma = sigma)

pp <- prcomp(MM, center=TRUE, scale.=TRUE)
pp
summary(pp)
fviz_pca_var(pp, addlabels = TRUE, repel = TRUE)

```

How are the results of this PCA different? Which predictors load together?

> Now, the two sets of correlated variables load onto different PC axes. Predictors 1, 2, and 3 load onto PC1 with 1 and 2 in the same direction and 3 in the other direction. Variables 4, 5, and 6 load onto PC2 all in the same direction. #FIXME


## Eigenanalysis

Use the `eigen` function and the correlation matrix for your simulated data you just created to do an eigenanalysis. Compare the results to the output of of your PCA and identify what each result component represents.

```{r}

ee <- eigen(cor(MM))

ee

```

> The "values" are the eignenvalues and represent the amount of total standardized variance accounted for by each PC. These values divided by the sum of the eigenvalues gives the propotion of variance accounted for by each PC. The "vectors" are the eigenvectors and represent the relative contribution of each variable to each PC. #FIXME


## Urbanization and plant divergence

Santangelo et al. (2020) planted 642 white clover plants from 290 families that were collected across an urbanization gradient and measured a suite of phenotypes on these individuals. The averages per family excluding families that had any missing data are in the dataset `Santangelo_familyMean.csv`. The metadata provided by the authors describing the columns is in this table:

| Column | Description | Type |
|--------|-------------|------|
| Family | Unique family identifier | Character/String |
| Distance_to_core  | Distance of plant population to city center (km) | Float |
| Time_to_germination | Family-mean time to germination (days) | Float |
| Days_to_flower | Family-mean days to opening of first flower | Float |
| Veget_biomass| Family-mean total biomass (g) of vegetative biomass | Float |
| Avg_bnr_wdth| Family-mean width (mm) of banner petals | Float |
| Avg_bnr_lgth | Family-mean length (mm) of banner petals | Float |
| Avg_stolon_thick | Family-mean thickness (i.e. diameter, mm) of stolons | Float |
| Avg_seeds_per_flower | Family-mean number of seeds produced per flower | Float |
| sex_asex | Family-mean ratio of vegetative to sexual reproductive biomass | Float 

Perform a PCA on the plant characteristics: use all of the variables except the urbanization measure (`Distance_to_core`). Examine the results of the PCA and visualize them and interpret the meaning of the major PCs. In doing so, determine how many of the PCs you think are meaningful. 

```{r}
#FIXME
DD <- read_csv("../Data/Santangelo_familyMean.csv",
               show_col_types = FALSE) 
glimpse(DD)

pca.dd <- prcomp(DD[,3:10], center = TRUE, scale. = TRUE)
pca.dd
summary(pca.dd)
fviz_pca_var(pca.dd, addlabels = TRUE, repel = TRUE)
fviz_pca_var(pca.dd, addlabels = TRUE, repel = TRUE, axes = c(2,3))

```

One of the goals of the paper was to determine how plant characteristics change along an urbanization gradient. This gradient was measured by the distance from the city center, which the authors showed correlates with other measures such as % impervious surface. 

For each of the PC's you decide are meaningful, perform an `lm` with the PC scores as the response variable and `Distance_to_core` as the predictor. 

```{r}
mod <- lm(pca.dd$x[,1] ~ DD$Distance_to_core)
summary(mod)

mod <- lm(pca.dd$x[,2] ~ DD$Distance_to_core)
summary(mod)

mod <- lm(pca.dd$x[,3] ~ DD$Distance_to_core)
summary(mod)
```

What would you conclude from this analysis? How do plants change as you move away from the city center?

>


