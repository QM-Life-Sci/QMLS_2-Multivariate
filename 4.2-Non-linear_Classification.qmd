---
title: "Flexible Classification"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
bibliography: Multivariate.bib
csl: evolution.csl
---


```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(cowplot)
library(mvtnorm)
library(rsample)
library(e1071) 

ggplot2::theme_set(theme_cowplot())

SD2 <- read_rds("Data/SD2.rds")
SD3 <- read_rds("Data/SD3.rds")
```


## *Linear* Discriminant Analysis

- Like a MANOVA in reverse
- Linear separation of groups


## Non-linear classifiers

1. Quadratic Discriminant Analysis `MASS::qda()`
    - Linear space is "mapped" to quadratic space
    - `X1 + X1^2 + X2 + X2^2`
2. Support Vector Machines [@Hastie2009-xa; @James2013-oe]


## Support Vector Machines

- Bypasses the polynomial expansion via a "kernel"
    - Linear, polynomial, radial, sigmoid
- [Why is a support vector machine called a machine?](https://www.quora.com/Why-is-a-support-vector-machine-called-a-machine)

![](https://www.dtreg.com/uploaded/pageimg/SvmMargin2.jpg)

<div class="ref">
[DTReg](https://www.dtreg.com/)
</div>


## SVM in R

- [`e1071` package](https://cran.r-project.org/web/packages/e1071/index.html): `svm()`
- [kernlab](https://cran.r-project.org/web/packages/kernlab/vignettes/kernlab.pdf): `ksvm()`
- [Applied Machine Learning Using mlr3 in R](https://mlr3book.mlr-org.com/)

```{r}
#| echo: true

library(e1071) 
```


## Simulated data

```{r}
ggplot(SD3, aes(X1, X2, color = Group)) +
  geom_point(size = 3) +
  coord_equal() +
  scale_color_brewer(type = "qual", palette = "Set1")
```


## Create training and testing sets

- [`rsample` package](https://rsample.tidymodels.org/index.html)
- Also [`cvTools`](https://cran.r-project.org/web/packages/cvTools/index.html) (among others)

```{r}
#| echo: true

library(rsample)

set.seed(34598734)

split <- initial_split(SD3, strata = Group, prop = 0.75) 

Training_set <- training(split) 
Test_set <- testing(split)
```


## Training and testing sets

```{r}
#| echo: true

Training_set |> count(Group)
Test_set |> count(Group)
```


## Fitting SVM to the Training set 

```{r}
#| echo: true
#| output-location: slide

SVM_fit <- svm(Group ~ ., 
               data = Training_set, 
               scale = TRUE,
               type = "C-classification", 
               kernel = "radial",
               cost = 5)
SVM_fit
```


## Predicting the Test set results 

```{r}
#| echo: true

(Group_pred <- predict(SVM_fit, newdata = Test_set[, -1]) )
```


## Confusion matrix

```{r}
#| echo: true

table(Test_set[, 1], Group_pred) 
```


## Predicting

```{r}
#| echo: true

Grid <- crossing(X1 = seq(min(SD3$X1), max(SD3$X1), length.out = 200),
                 X2 = seq(min(SD3$X2), max(SD3$X2), length.out = 200))
Grid <- Grid |> 
  mutate(Train_pred = predict(SVM_fit, newdata = Grid))

head(Grid)
```


## Plotting the results 

```{r}
P3 <- ggplot() +
  geom_tile(data = Grid, aes(X1, X2, fill = Train_pred), alpha = 0.25) +
  geom_point(data = Training_set, aes(X1, X2, color = Group)) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  theme(legend.position = "none") +
  labs(title = "SVM Training")

# Plotting the test data set results 
P4 <- ggplot() +
  geom_tile(data = Grid, aes(X1, X2, fill = Train_pred), alpha = 0.25) +
  geom_point(data = Test_set, aes(X1, X2, color = Group)) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  theme(legend.position = "none") +
  labs(title = "SVM Testing")

plot_grid(P3, P4)
```


## Complex patterns

```{r}
set.seed(347937)

n <- 500

X <- rmvnorm(n, mean = c(0, 0)) |> as.data.frame() |> 
  rename(X1 = V1,
         X2 = V2)

CP <- data.frame(X) |> 
  mutate(Group = if_else(X1^2 + X2^2 <= 1, "A", "B") |> factor()) |> 
  relocate(Group)

ggplot(CP, aes(X1, X2, color = Group)) +
  geom_point(size = 3) +
  coord_equal() +
  scale_color_brewer(type = "qual", palette = "Set1")

split <- initial_split(CP, strata = Group, prop = 0.75) 

Training_set <- training(split) 
Test_set <- testing(split)

# Fitting SVM to the Training set 
SVM_fit <- svm(Group ~ X1 + X2, 
               data = Training_set, 
               scale = TRUE,
               type = "C-classification", 
               kernel = "radial",
               cost = 5) 

# Predicting the Test set results 
Group_pred <- predict(SVM_fit, newdata = Test_set[, -1]) 
```


## Plotting the results 

```{r}
Grid <- crossing(X1 = seq(min(CP$X1), max(CP$X1), length.out = 200),
                 X2 = seq(min(CP$X2), max(CP$X2), length.out = 200))

Grid <- Grid |> 
  mutate(Train_pred = predict(SVM_fit, newdata = Grid))

P1 <- ggplot() +
  geom_tile(data = Grid, aes(X1, X2, fill = Train_pred), alpha = 0.25) +
  geom_point(data = Training_set, aes(X1, X2, color = Group)) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  theme(legend.position = "none") +
  labs(title = "SVM Training")

# Plotting the test data set results 
P2 <- ggplot() +
  geom_tile(data = Grid, aes(X1, X2, fill = Train_pred), alpha = 0.25) +
  geom_point(data = Test_set, aes(X1, X2, color = Group)) +
  scale_color_brewer(type = "qual", palette = "Set1") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  theme(legend.position = "none") +
  labs(title = "SVM Testing")

plot_grid(P1, P2)
```


## Application to Fly Diets

```{r}
FD <- read_csv("./Data/PreProcessed_Expr.csv",
               show_col_types = FALSE) |> 
  dplyr::select(-patRIL) |> 
  mutate(Treat = factor(Treat)) |> 
  as.data.frame()

set.seed(94875)

split <- initial_split(FD, strata = Treat, prop = 0.75) 

Training_set <- training(split) 
Test_set <- testing(split)
```

```{r}
#| echo: true
Training_set |> count(Treat)
Test_set |> count(Treat)
```


## Fitting SVM to the Training set 

```{r}
#| echo: true
#| output-location: slide
library(kernlab)

SVM_fit <- svm(Treat ~ ., 
               data = Training_set, 
               scale = TRUE,
               type = "C-classification", 
               kernel = "radial",
               cost = 2)
SVM_fit
```


## Predicting the Test set results 

```{r}
#| echo: true

(Group_pred <- predict(SVM_fit, newdata = Test_set[, -1]) )
```


## Confusion matrix

```{r}
#| echo: true

table(Test_set[, 1], Group_pred) 
```


## Plotting

```{r}
plot(SVM_fit,
     data = Training_set,
     formula = Dm01792789_g1 ~ Dm01793858_g1)
```


## Plotting

```{r}
plot(SVM_fit,
     data = Training_set,
     formula = Dm01792789_g1 ~ Dm01798339_g1)
```


## Going further

- Continuous prediction instead of classification?
    - "Regression" with SVM is possible
- What predictors are important for classification?
    - "Feature importance"
    - [`mlr3verse` packages](https://mlr3book.mlr-org.com/)
- Other "learners": [https://mlr-org.com/learners.html](https://mlr-org.com/learners.html)
    

## References

::: {#refs}
:::

